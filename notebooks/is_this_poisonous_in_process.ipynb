{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gptix/is-this-poisonous/blob/master/is_this_poisonous.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SDIEZNkiE4OC"
   },
   "source": [
    "# Can I Eat This Project\n",
    "Lambda School Data Science cohort 10\n",
    "\n",
    "## Requirements\n",
    "\n",
    "See checklist at bottom of this notebook.\n",
    "\n",
    "### At present, this notebook and other work are designed to fulfill the MVP requirements.\n",
    "\n",
    "## Data\n",
    "Data gotten from UCI **UC Irvine Machine Learning Repository**\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Mushroom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTnDiT9bE4OF"
   },
   "source": [
    "# Model Interpretation\n",
    "\n",
    "- Visualize and interpret **partial dependence plots**\n",
    "- Explain individual predictions with **shapley value plots**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BPE_NGJE4OG"
   },
   "source": [
    "### Three types of model explanations this unit:\n",
    "\n",
    "#### 1. Global model explanation: all features in relation to each other _(Last lesson)_\n",
    "- Feature Importances: _Default, fastest, good for first estimates_\n",
    "- Drop-Column Importances: _The best in theory, but much too slow in practice_\n",
    "- Permutaton Importances: _A good compromise!_\n",
    "\n",
    "#### 2. Global model explanation: individual feature(s) in relation to target _(This lesson)_\n",
    "- Partial Dependence plots\n",
    "\n",
    "#### 3. Individual prediction explanation _(This lesson)_\n",
    "- Shapley Values\n",
    "\n",
    "_Note that the coefficients from a linear model give you all three types of explanations!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwLpflToE4OH"
   },
   "source": [
    "### Links\n",
    "\n",
    "#### Partial Dependence Plots\n",
    "- [Kaggle / Dan Becker: Machine Learning Explainability — Partial Dependence Plots](https://www.kaggle.com/dansbecker/partial-plots)\n",
    "- [Christoph Molnar: Interpretable Machine Learning — Partial Dependence Plots](https://christophm.github.io/interpretable-ml-book/pdp.html) + [animated explanation](https://twitter.com/ChristophMolnar/status/1066398522608635904)\n",
    "- [pdpbox repo](https://github.com/SauceCat/PDPbox) & [docs](https://pdpbox.readthedocs.io/en/latest/)\n",
    "\n",
    "#### Shapley Values\n",
    "- [Kaggle / Dan Becker: Machine Learning Explainability — SHAP Values](https://www.kaggle.com/learn/machine-learning-explainability)\n",
    "- [Christoph Molnar: Interpretable Machine Learning — Shapley Values](https://christophm.github.io/interpretable-ml-book/shapley.html)\n",
    "- [SHAP repo](https://github.com/slundberg/shap) & [docs](https://shap.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S65K1pqAE4OH"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
    "\n",
    "Libraries:\n",
    "\n",
    "- category_encoders\n",
    "- matplotlib\n",
    "- numpy\n",
    "- pandas\n",
    "- [**pdpbox**](https://github.com/SauceCat/PDPbox)\n",
    "- plotly\n",
    "- scikit-learn\n",
    "- scipy.stats\n",
    "- [**shap**](https://github.com/slundberg/shap)\n",
    "- xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITYmrjRmE4OI"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "    !pip install pdpbox\n",
    "    !pip install shap\n",
    "\n",
    "# If local:\n",
    "else:\n",
    "    DATA_PATH = '../data/'\n",
    "    !pip install xgboost\n",
    "\n",
    "# Ignore this warning: https://github.com/dmlc/xgboost/issues/4300\n",
    "# xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0psa75sE4OL"
   },
   "source": [
    "## Ingest data and make it useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKZ1Z7OkE4OM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# I made the column names by copying descriptions from the file './data/agaricus-lepiota.names',\n",
    "# then used lisp to extract column names, replace '-' with '_', then build a python list of strings.\n",
    "\n",
    "colnames = [\"poisonous_edible\", \"cap_shape\", \"cap_surface\", \"cap_color\", \"bruises?\", \"odor\", \"gill_attachment\",\n",
    "           \"gill_spacing\", \"gill_size\", \"gill_color\", \"stalk_shape\", \"stalk_root\", \n",
    "           \"stalk_surface_above_ring\", \"stalk_surface_below_ring\", \"stalk_color_above_ring\", \n",
    "           \"stalk_color_below_ring\", \"veil_type\", \"veil_color\", \"ring_number\", \"ring_type\", \n",
    "           \"spore_print_color\", \"population\", \"habitat\"]\n",
    "\n",
    "# colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poisonous_edible</th>\n",
       "      <th>cap_shape</th>\n",
       "      <th>cap_surface</th>\n",
       "      <th>cap_color</th>\n",
       "      <th>bruises?</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill_attachment</th>\n",
       "      <th>gill_spacing</th>\n",
       "      <th>gill_size</th>\n",
       "      <th>gill_color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk_surface_below_ring</th>\n",
       "      <th>stalk_color_above_ring</th>\n",
       "      <th>stalk_color_below_ring</th>\n",
       "      <th>veil_type</th>\n",
       "      <th>veil_color</th>\n",
       "      <th>ring_number</th>\n",
       "      <th>ring_type</th>\n",
       "      <th>spore_print_color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>CONVEX</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>BRUISES</td>\n",
       "      <td>ALMOND</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CROWDED</td>\n",
       "      <td>NARROW</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>...</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>PENDANT</td>\n",
       "      <td>PURPLE</td>\n",
       "      <td>SEVERAL</td>\n",
       "      <td>WOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>CONVEX</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>BRUISES</td>\n",
       "      <td>ALMOND</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CROWDED</td>\n",
       "      <td>NARROW</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>...</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>PENDANT</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>SEVERAL</td>\n",
       "      <td>WOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>CONVEX</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>BRUISES</td>\n",
       "      <td>ALMOND</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CROWDED</td>\n",
       "      <td>NARROW</td>\n",
       "      <td>PINK</td>\n",
       "      <td>...</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>PENDANT</td>\n",
       "      <td>PURPLE</td>\n",
       "      <td>SEVERAL</td>\n",
       "      <td>WOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>CONVEX</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>BRUISES</td>\n",
       "      <td>ALMOND</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CROWDED</td>\n",
       "      <td>NARROW</td>\n",
       "      <td>PINK</td>\n",
       "      <td>...</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>PENDANT</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>SEVERAL</td>\n",
       "      <td>WOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>CONVEX</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>BRUISES</td>\n",
       "      <td>ALMOND</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CROWDED</td>\n",
       "      <td>NARROW</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>...</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>PENDANT</td>\n",
       "      <td>PURPLE</td>\n",
       "      <td>SEVERAL</td>\n",
       "      <td>WOODS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  poisonous_edible cap_shape cap_surface cap_color bruises?    odor  \\\n",
       "0           EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
       "1           EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
       "2           EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
       "3           EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
       "4           EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
       "\n",
       "  gill_attachment gill_spacing gill_size gill_color  ...  \\\n",
       "0            FREE      CROWDED    NARROW      WHITE  ...   \n",
       "1            FREE      CROWDED    NARROW      WHITE  ...   \n",
       "2            FREE      CROWDED    NARROW       PINK  ...   \n",
       "3            FREE      CROWDED    NARROW       PINK  ...   \n",
       "4            FREE      CROWDED    NARROW      BROWN  ...   \n",
       "\n",
       "  stalk_surface_below_ring stalk_color_above_ring stalk_color_below_ring  \\\n",
       "0                   SMOOTH                  WHITE                  WHITE   \n",
       "1                   SMOOTH                  WHITE                  WHITE   \n",
       "2                   SMOOTH                  WHITE                  WHITE   \n",
       "3                   SMOOTH                  WHITE                  WHITE   \n",
       "4                   SMOOTH                  WHITE                  WHITE   \n",
       "\n",
       "  veil_type veil_color ring_number ring_type spore_print_color population  \\\n",
       "0   PARTIAL      WHITE         ONE   PENDANT            PURPLE    SEVERAL   \n",
       "1   PARTIAL      WHITE         ONE   PENDANT             BROWN    SEVERAL   \n",
       "2   PARTIAL      WHITE         ONE   PENDANT            PURPLE    SEVERAL   \n",
       "3   PARTIAL      WHITE         ONE   PENDANT             BROWN    SEVERAL   \n",
       "4   PARTIAL      WHITE         ONE   PENDANT            PURPLE    SEVERAL   \n",
       "\n",
       "  habitat  \n",
       "0   WOODS  \n",
       "1   WOODS  \n",
       "2   WOODS  \n",
       "3   WOODS  \n",
       "4   WOODS  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a file named 'expanded' is a CSV file with 'full-word' values instead of single-letter abbreviations.\n",
    "df = pd.read_csv(DATA_PATH+'expanded', skiprows=9, skipfooter=1, \n",
    "                 engine='python', names=colnames, header=None)\n",
    "df.head()\n",
    "# df.tail()\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataframe into **X** matrix and $\\hat{y}$ vector\n",
    "\n",
    "We will use the 22 features to 'predict' whether an observed mushroom is poisonous or not.\n",
    "\n",
    "$\\hat{y}$ is simply the series of 'POISONOUS' and 'EDIBLE' values.\n",
    "\n",
    "And **X** is the matrix of all other series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"poisonous_edible\"\n",
    "features = df.columns.drop(target)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categorical values in $\\hat{y}$ into numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EDIBLE', 'POISONOUS', 'POISONOUS']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform string values to category values, then to integers\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(y)\n",
    "list(le.classes_)\n",
    "\n",
    "y = le.transform(y)\n",
    "\n",
    "# Note: EDIBLE = 0, POISONOUS = 1\n",
    "# since this mutates the data in y, transforming again will lose the relation between the old, string \n",
    "# data and the new, numeric data.\n",
    "# To get back, re-run code at and after definition of df.\n",
    "\n",
    "# Get sample of inversion of transformation.\n",
    "list(le.inverse_transform([0, 1, 1]))\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split **X** and $\\hat{y}$ into subsets for training, validation, and final testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split train into train & val\n",
    "# train, test = train_test_split(df, train_size=0.90, test_size=0.10, random_state=43)\n",
    "# train, val = train_test_split(train, train_size=0.90, test_size=0.10, random_state=43)\n",
    "\n",
    "# The 'train' data from this step will be split again, below.\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# In the line below, 'test_size' is used to specify the size of the val set.\n",
    "X_train, X_val, y_train, y_val = train_test_split( X_train, y_train, test_size=0.11, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X_train), len(X_val), len(X_test))\n",
    "# pdy =pd.DataFrame(y)\n",
    "# pdy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21GZsDZxE4OS"
   },
   "source": [
    "## Basic histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['poisonous_edible'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a baseline, to use in evaluating subsequent models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "UJeSWgkTE4OQ",
    "lines_to_next_cell": 2,
    "outputId": "e37d4c5f-e7b1-4f85-990a-73a1e5e8f50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline, guessing 'edible', would be right 53.3% of the time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a baseline\n",
    "baseline_edible = df['poisonous_edible'].value_counts(normalize=True).max()\n",
    "print(f'Baseline, guessing \\'edible\\', would be right {round(100 * baseline_edible,1)}% of the time.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Build and) Fit a Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "7MN7rsuVE4OS",
    "lines_to_next_cell": 2,
    "outputId": "46ace54e-5ff8-48da-dc84-cefd26441ba5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('targetencoder',\n",
       "                 TargetEncoder(cols=['cap_shape', 'cap_surface', 'cap_color',\n",
       "                                     'bruises?', 'odor', 'gill_attachment',\n",
       "                                     'gill_spacing', 'gill_size', 'gill_color',\n",
       "                                     'stalk_shape', 'stalk_root',\n",
       "                                     'stalk_surface_above_ring',\n",
       "                                     'stalk_surface_below_ring',\n",
       "                                     'stalk_color_above_ring',\n",
       "                                     'stalk_color_below_ring', 'veil_type',\n",
       "                                     'veil_color', 'ring_number', 'ring_type',\n",
       "                                     'spore_print_color', 'population',\n",
       "                                     'habitat'],\n",
       "                               drop_invariant=False, handle_missing='value',\n",
       "                               handle_unknown='value', min_samples_leaf=1,\n",
       "                               return_df=True, smoothing=1.0, verbose=0)),\n",
       "                ('linearregression',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to convert categorical values to numeric values. \n",
    "import category_encoders as ce\n",
    "\n",
    "# We will use a straightforward linear regression.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# We will use 'make_pipeline' to create a 'composition' of two classes.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# This instantiates and composes.  Really cool.\n",
    "lr = make_pipeline(\n",
    "    ce.TargetEncoder(),  \n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# Use the instance of the model to fit to training features, and evaluate with training target output.\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Linear Model using **R^2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R^2 0.9644133999445964\n"
     ]
    }
   ],
   "source": [
    "print('Linear Regression R^2', lr.score(X_val, y_val))#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zn1hiBRLE4OU"
   },
   "source": [
    "### Explaining Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "id": "HaPnYdugE4OV",
    "outputId": "6979240a-49a6-4c45-ffea-79992d851fad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cap_shape                  -6.761478e-02\n",
       "cap_surface                -4.069967e-03\n",
       "cap_color                   6.904132e-02\n",
       "bruises?                   -8.356050e-02\n",
       "odor                        8.659845e-01\n",
       "gill_attachment            -8.241986e-01\n",
       "gill_spacing               -4.625803e-04\n",
       "gill_size                   1.875690e-01\n",
       "gill_color                  1.347181e-02\n",
       "stalk_shape                -6.142119e-02\n",
       "stalk_root                 -2.523471e-01\n",
       "stalk_surface_above_ring    2.987629e-02\n",
       "stalk_surface_below_ring   -3.658720e-02\n",
       "stalk_color_above_ring      4.983177e-03\n",
       "stalk_color_below_ring      3.828047e-02\n",
       "veil_type                  -8.326673e-17\n",
       "veil_color                  3.418248e-01\n",
       "ring_number                -1.960591e-01\n",
       "ring_type                  -9.430129e-03\n",
       "spore_print_color           2.312993e-01\n",
       "population                  1.107353e-01\n",
       "habitat                    -4.841940e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = lr.named_steps['linearregression'].coef_\n",
    "pd.Series(coefficients, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Build and) Fit a Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.986810551558753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    DecisionTreeClassifier(max_depth=3)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Accuracy of Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.986810551558753\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy: ', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Recall Score of DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Recall:  0.9842931937172775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "# y_pred\n",
    "recall_score = recall_score(y_val, y_pred)\n",
    "print('Validation Recall: ', recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/74/dbed754c0abd63768d3a7a7b472da35b08ac442cf87d73d5850a6f32391e/graphviz-0.13.2-py2.py3-none-any.whl\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.13.2\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-48febb7c04df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Vizualize Decision Tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "!pip install graphviz\n",
    "\n",
    "# Vizualize Decision Tree\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "tree = pipeline.named_steps['decisiontreeclassifier']\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "    tree,\n",
    "    out_file = None,\n",
    "    feature_names = X_train.columns,\n",
    "    class_names = y.unique().astype(str),\n",
    "    filled = True,\n",
    "    impurity=False,\n",
    "    proportion=True,\n",
    ")\n",
    "\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NswvbYBnE4OW"
   },
   "source": [
    "### Fit Gradient Boosting model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "lysBK8sxE4OX",
    "lines_to_next_cell": 2,
    "outputId": "9096804b-f7fd-48d2-cad2-8c87f23a0ea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/gt/.local/share/virtualenvs/is-this-poisonous-SRj9DW7X/lib/python3.7/site-packages (0.90)\n",
      "Requirement already satisfied: scipy in /home/gt/.local/share/virtualenvs/is-this-poisonous-SRj9DW7X/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /home/gt/.local/share/virtualenvs/is-this-poisonous-SRj9DW7X/lib/python3.7/site-packages (from xgboost) (1.18.1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7688329ed767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install xgboost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m gb = make_pipeline(\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "gb = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    XGBRegressor(n_estimators=200, objective='reg:squarederror', n_jobs=-1)\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_val)\n",
    "print('Gradient Boosting R^2', r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUl0gWC9E4OY"
   },
   "source": [
    "### Explaining Gradient Boosting???\n",
    "\n",
    "Linear models have coefficients, but tree ensembles do not.\n",
    "\n",
    "Instaed, to see the relationship between individual feature(s) and the target, we can use partial dependence plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9AhfUucKE4Oa"
   },
   "source": [
    "## Partial Dependence Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQb6FbwQE4Ob"
   },
   "source": [
    "From [PDPbox documentation](https://pdpbox.readthedocs.io/en/latest/):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "093kfEwfE4Ob"
   },
   "source": [
    ">**The common headache**: When using black box machine learning algorithms like random forest and boosting, it is hard to understand the relations between predictors and model outcome. For example, in terms of random forest, all we get is the feature importance. Although we can know which feature is significantly influencing the outcome based on the importance calculation, it really sucks that we don’t know in which direction it is influencing. And in most of the real cases, the effect is non-monotonic. We need some powerful tools to help understanding the complex relations between predictors and model prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANlrBZeeE4Oc"
   },
   "source": [
    "[Animation by Christoph Molnar](https://twitter.com/ChristophMolnar/status/1066398522608635904), author of [_Interpretable Machine Learning_](https://christophm.github.io/interpretable-ml-book/pdp.html#examples)\n",
    "\n",
    "> Partial dependence plots show how a feature affects predictions of a Machine Learning model on average.\n",
    "> 1. Define grid along feature\n",
    "> 2. Model predictions at grid points\n",
    "> 3. Line per data instance -> ICE (Individual Conditional Expectation) curve\n",
    "> 4. Average curves to get a PDP (Partial Dependence Plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AdIOTNtlE4Oc"
   },
   "source": [
    "## Partial Dependence Plots with 1 feature\n",
    "\n",
    "#### PDPbox\n",
    "- [Gallery](https://github.com/SauceCat/PDPbox#gallery)\n",
    "- [API Reference: pdp_isolate](https://pdpbox.readthedocs.io/en/latest/pdp_isolate.html)\n",
    "- [API Reference: pdp_plot](https://pdpbox.readthedocs.io/en/latest/pdp_plot.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVe6EogDE4Od"
   },
   "outputs": [],
   "source": [
    "# Later, when you save matplotlib images to include in blog posts or web apps,\n",
    "# increase the dots per inch (double it), so the text isn't so fuzzy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSvdqXyvE4Of",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "\n",
    "feature = 'Annual Income'\n",
    "\n",
    "isolated = pdp_isolate(\n",
    "    model=gb, \n",
    "    dataset=X_val, \n",
    "    model_features=X_val.columns, \n",
    "    feature=feature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "D1hqtlh4lhln",
    "outputId": "e3c982aa-dc93-45b3-c430-f285133a4a74"
   },
   "outputs": [],
   "source": [
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BoOcAu6nliP5"
   },
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "dSVTcE37OswM",
    "outputId": "24e6b7de-29af-43d7-b33e-4b64a4b58397"
   },
   "outputs": [],
   "source": [
    "pdp_plot(isolated, feature_name=feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "NjlqIvz2PHMa",
    "outputId": "bd4f8867-f9e6-4a4f-d6d2-6011e557f95f"
   },
   "outputs": [],
   "source": [
    "pdp_plot(isolated, feature_name=feature)\n",
    "plt.xlim((20000,150000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "ITNcRD09SXPq",
    "outputId": "ea8bfcf0-15c1-4190-9148-b52d6a8ee702"
   },
   "outputs": [],
   "source": [
    "# Plot PDP with 100 ICE curves\n",
    "# PDP: Partial Dependence Plot\n",
    "# ICE: Individual Conditional Expectation\n",
    "pdp_plot(isolated, feature_name=feature, plot_lines=True, \n",
    "         frac_to_plot=0.01)\n",
    "\n",
    "plt.xlim(20000,150000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "5lnmMZGHTMjb",
    "outputId": "be397f38-6556-4e72-f659-97cfd3b8824d"
   },
   "outputs": [],
   "source": [
    "isolated = pdp_isolate(\n",
    "    model=gb, \n",
    "    dataset=X_val, \n",
    "    model_features=X_val.columns, \n",
    "    feature=feature, \n",
    "    num_grid_points=50\n",
    ")\n",
    "\n",
    "# How many predictions are required to make a PDP with 1 feature,\n",
    "# given the size of our dataset, and the number of grid points?\n",
    "len(X_val) * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "O6NlUFw8ThFt",
    "outputId": "959aa3b6-b484-4ad2-ebc7-7ffaa30263e0"
   },
   "outputs": [],
   "source": [
    "pdp_plot(isolated, feature_name=feature, plot_lines=True, \n",
    "         frac_to_plot=0.01)\n",
    "\n",
    "plt.xlim(20000,150000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyeQ2srLE4Og"
   },
   "source": [
    "## Partial Dependence Plots with 2 features\n",
    "\n",
    "See interactions!\n",
    "\n",
    "PDPbox\n",
    "- [Gallery](https://github.com/SauceCat/PDPbox#gallery)\n",
    "- [API Reference: pdp_interact](https://pdpbox.readthedocs.io/en/latest/pdp_interact.html)\n",
    "- [API Reference: pdp_interact_plot](https://pdpbox.readthedocs.io/en/latest/pdp_interact_plot.html)\n",
    "\n",
    "Be aware of a bug in PDPBox version <= 0.20:\n",
    "- With the `pdp_interact_plot` function, `plot_type='contour'` gets an error, but `plot_type='grid'` works\n",
    "- This will be fixed in the next release of PDPbox: https://github.com/SauceCat/PDPbox/issues/40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVrS2mbUE4Oh",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from pdpbox.pdp import pdp_interact, pdp_interact_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ghJry3-bUJAw"
   },
   "outputs": [],
   "source": [
    "features = ['Annual Income', 'Credit Score']\n",
    "\n",
    "interaction = pdp_interact(\n",
    "    model=gb, \n",
    "    dataset=X_val,\n",
    "    model_features=X_val.columns, \n",
    "    features=features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "UkwynYMrUbfV",
    "outputId": "5ac7f4fa-0b2e-45e4-c63e-5343859f6b14"
   },
   "outputs": [],
   "source": [
    "pdp_interact_plot(interaction, plot_type='grid', \n",
    "                  feature_names=features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6dptuu4E4Oi"
   },
   "source": [
    "### BONUS: 3D with Plotly!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOWOfaoGE4Oj",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# First, make the 2D plot above. Then ...\n",
    "\n",
    "pdp = interaction.pdp.pivot_table(\n",
    "    values='preds', \n",
    "    columns=features[0], \n",
    "    index=features[1]\n",
    ")[::-1] # Slice notation to reverse index order so y axis is ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "Fh2LAeAqE4Ok",
    "outputId": "6a839a1b-8c36-43cd-fd8d-2c50f9b16edb"
   },
   "outputs": [],
   "source": [
    "pdp = pdp.drop(columns=[1000.0, 751329.0])\n",
    "\n",
    "pdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "nKO_3QZ2E4Om",
    "outputId": "24bc6061-7a7e-4923-95e7-364f463c5adf"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "surface = go.Surface(\n",
    "    x=pdp.columns, \n",
    "    y=pdp.index, \n",
    "    z=pdp.values\n",
    ")\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(title=features[0]), \n",
    "        yaxis=dict(title=features[1]), \n",
    "        zaxis=dict(title=target)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(surface, layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "VuNKQhGYVd-P",
    "outputId": "f3460d2b-5140-4f4a-b8a0-8d134a54b5e8"
   },
   "outputs": [],
   "source": [
    "# Number of predictions required to make a PDP with 2 feature\n",
    "# given the size of your dataset, and the number of grid points:\n",
    "len(X_val) * 10**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZvAeOaqiE4On"
   },
   "source": [
    "# BONUS: PDPs with categorical features\n",
    "\n",
    "1. I recommend you use Ordinal Encoder or Target Encoder, outside of a pipeline, to encode your data first. (If there is a natural ordering, then take the time to encode it that way, instead of random integers.) Then use the encoded data with pdpbox.\n",
    "2. There's some extra work to get readable category names on your plot, instead of integer category codes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "diA2v6qEE4Oo",
    "outputId": "2eb395d2-eb87-42c9-f3cf-897f08dd9c5f"
   },
   "outputs": [],
   "source": [
    "# Fit a model on Titanic data\n",
    "import category_encoders as ce\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "df.age = df.age.fillna(df.age.median())\n",
    "df = df.drop(columns='deck')\n",
    "df = df.dropna()\n",
    "\n",
    "target = 'survived'\n",
    "features = df.columns.drop(['survived', 'alive'])\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Use Ordinal Encoder, outside of a pipeline\n",
    "encoder = ce.OrdinalEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_encoded, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "dR5gBm0UE4Op",
    "outputId": "19bc6fe2-138a-40c2-8c3e-b06aa22d90e7"
   },
   "outputs": [],
   "source": [
    "# Use Pdpbox\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pdpbox import pdp\n",
    "feature = 'sex'\n",
    "pdp_dist = pdp.pdp_isolate(model=model, dataset=X_encoded, model_features=features, feature=feature)\n",
    "pdp.pdp_plot(pdp_dist, feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "4Jz01-SbE4Os",
    "outputId": "e2e369b3-15db-4ada-d786-c6244267924e"
   },
   "outputs": [],
   "source": [
    "# Look at the encoder's mappings\n",
    "encoder.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "PCZIxiPRE4Ou",
    "outputId": "632b8934-d5f5-4991-8ee5-9832bd43dedf"
   },
   "outputs": [],
   "source": [
    "pdp.pdp_plot(pdp_dist, feature)\n",
    "\n",
    "# Manually change the xticks labels\n",
    "plt.xticks([1, 2], ['male', 'female']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2lhkwFgE4Ow"
   },
   "outputs": [],
   "source": [
    "# Let's automate it\n",
    "\n",
    "feature = 'sex'\n",
    "for item in encoder.mapping:\n",
    "    if item['col'] == feature:\n",
    "        feature_mapping = item['mapping']\n",
    "        \n",
    "feature_mapping = feature_mapping[feature_mapping.index.dropna()]\n",
    "category_names = feature_mapping.index.tolist()\n",
    "category_codes = feature_mapping.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "ktEddhKhE4Ox",
    "outputId": "c61bd238-295a-4651-a177-892d8209dda0"
   },
   "outputs": [],
   "source": [
    "pdp.pdp_plot(pdp_dist, feature)\n",
    "\n",
    "# Automatically change the xticks labels\n",
    "plt.xticks(category_codes, category_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "Y2fddArIE4Oy",
    "outputId": "d9e16992-bb0f-4bad-c448-6753d41bcd99"
   },
   "outputs": [],
   "source": [
    "features = ['sex', 'age']\n",
    "\n",
    "interaction = pdp_interact(\n",
    "    model=model, \n",
    "    dataset=X_encoded, \n",
    "    model_features=X_encoded.columns, \n",
    "    features=features\n",
    ")\n",
    "\n",
    "pdp_interact_plot(interaction, plot_type='grid', feature_names=features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "colab_type": "code",
    "id": "XpNd3kCHE4O0",
    "lines_to_next_cell": 0,
    "outputId": "d5aa26f0-eaf8-4ffd-b1aa-2e8149fdc196"
   },
   "outputs": [],
   "source": [
    "pdp = interaction.pdp.pivot_table(\n",
    "    values='preds', \n",
    "    columns=features[0], # First feature on x axis\n",
    "    index=features[1]    # Next feature on y axis\n",
    ")[::-1]  # Reverse the index order so y axis is ascending\n",
    "\n",
    "pdp = pdp.rename(columns=dict(zip(category_codes, category_names)))\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(pdp, annot=True, fmt='.2f', cmap='viridis')\n",
    "plt.title('Partial Dependence of Titanic survival, on sex & age');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IuqqK9pIE4O1"
   },
   "source": [
    "# Explain individual predictions with shapley value plots\n",
    "\n",
    "## Regression: NYC Apartment Rents\n",
    "\n",
    "_**Coming full circle!**_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPT5KCQ6E4O1",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read New York City apartment rental listing data\n",
    "df = pd.read_csv(DATA_PATH+'apartments/renthop-nyc.csv')\n",
    "assert df.shape == (49352, 34)\n",
    "\n",
    "# Remove the most extreme 1% prices,\n",
    "# the most extreme .1% latitudes, &\n",
    "# the most extreme .1% longitudes\n",
    "df = df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n",
    "        (df['price'] <= np.percentile(df['price'], 99.5)) & \n",
    "        (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n",
    "        (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n",
    "        (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n",
    "        (df['longitude'] <= np.percentile(df['longitude'], 99.95))]\n",
    "\n",
    "# Do train/test split\n",
    "# Use data from April & May 2016 to train\n",
    "# Use data from June 2016 to test\n",
    "df['created'] = pd.to_datetime(df['created'], infer_datetime_format=True)\n",
    "cutoff = pd.to_datetime('2016-06-01')\n",
    "train = df[df.created < cutoff]\n",
    "test  = df[df.created >= cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lBCK7Y8IE4O3"
   },
   "source": [
    "_**Remember this code you wrote for your first assignment?**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-ga_JTlE4O3",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Arrange X features matrix & y target vector\n",
    "features = ['bedrooms', 'bathrooms']\n",
    "target = 'price'\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Fit model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "def predict(bedrooms, bathrooms):\n",
    "    y_pred = model.predict([[bedrooms, bathrooms]])\n",
    "    estimate = y_pred[0]\n",
    "    bed_coef = model.coef_[0]\n",
    "    bath_coef = model.coef_[1]\n",
    "    \n",
    "    # Format with $ and comma separators. No decimals.\n",
    "    result = f'Rent for a {bedrooms}-bed, {bathrooms}-bath apartment in NYC is estimated at ${estimate:,.0f}.'\n",
    "    explanation = f' In this model, each bedroom adds ${bed_coef:,.0f} & each bathroom adds ${bath_coef:,.0f}.'\n",
    "    return result + explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fp2COULjE4O4"
   },
   "source": [
    "_**Let's do something similar, but with a tuned Random Forest and Shapley Values.**_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdN2HJZvE4O5"
   },
   "outputs": [],
   "source": [
    "# Assign to X, y\n",
    "features = ['bedrooms', 'bathrooms', 'longitude', 'latitude']\n",
    "target = 'price'\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "rguQ59j0E4O7",
    "outputId": "31e2f6c9-588a-48f4-e48b-ffe630f55dcc"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = { \n",
    "    'n_estimators': randint(50, 500), \n",
    "    'max_depth': [5, 10, 15, 20, None], \n",
    "    'max_features': uniform(0, 1), \n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=5, \n",
    "    cv=2, \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "rLWlbtjOE4O9",
    "lines_to_next_cell": 2,
    "outputId": "f225c74e-2f78-47c9-f39c-d979ab942603"
   },
   "outputs": [],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation MAE', -search.best_score_)\n",
    "model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pchuM1I1E4O_"
   },
   "source": [
    "## Explain individual predictions with shapley value plots\n",
    "\n",
    "#### [Dan Becker explains Shapley Values:](https://www.kaggle.com/dansbecker/shap-values)\n",
    "\n",
    ">You've seen (and used) techniques to extract general insights from a machine learning model. But what if you want to break down how the model works for an individual prediction?\n",
    "\n",
    ">SHAP Values (an acronym from SHapley Additive exPlanations) break down a prediction to show the impact of each feature. \n",
    "\n",
    ">There is some complexity to the technique ... We won't go into that detail here, since it isn't critical for using the technique. [This blog post](https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d) has a longer theoretical explanation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_X_RJHSE4O_"
   },
   "outputs": [],
   "source": [
    "# Get an individual observation to explain.\n",
    "# For example, the 0th row from the test set.\n",
    "\n",
    "row = X_test.iloc[[0]]  # Dataframe with a single row (double brackets keeps it a dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "dm2NbY3cE4PB",
    "outputId": "0b2adaac-411f-4afb-941e-49ced2311c5b"
   },
   "outputs": [],
   "source": [
    "# What was the actual rent for this apartment?\n",
    "y_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "wqZRY53YE4PC",
    "outputId": "7ff7ab78-afe4-4f91-b509-1ccd994e7b5a"
   },
   "outputs": [],
   "source": [
    "# What does the model predict for this apartment?\n",
    "model.predict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "X3taRMx9E4PD",
    "outputId": "3514ed35-98c1-4109-add1-88db961c3020"
   },
   "outputs": [],
   "source": [
    "# Why did the model predict this?\n",
    "# Look at a Shapley Values Force Plot\n",
    "\n",
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(row)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value, \n",
    "    shap_values=shap_values,\n",
    "    features=row\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "AICaSx6fZyWb",
    "outputId": "33c9b9ea-11c8-4712-e328-bc135d12d9ae"
   },
   "outputs": [],
   "source": [
    "# Base value is approximately equal to the mean baseline\n",
    "explainer.expected_value, y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "cOiDweCxaNsh",
    "outputId": "7e6fff45-dfd3-4bae-83ff-260c94344378"
   },
   "outputs": [],
   "source": [
    "feature_names = row.columns\n",
    "feature_values = row.values[0]\n",
    "shaps = pd.Series(shap_values[0], zip(feature_names, feature_values))\n",
    "shaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "1AYn3xpabKo5",
    "outputId": "fe30f0fc-5499-484c-dfc9-85e8cd0a8ec8"
   },
   "outputs": [],
   "source": [
    "shaps.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "8e4OLEU2bOl1",
    "outputId": "2a1f0251-d696-46dd-a460-9594bab5d179"
   },
   "outputs": [],
   "source": [
    "explainer.expected_value + shaps.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1ZB8yOGE4PE"
   },
   "source": [
    "### Define the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "qaiO9bJQE4PF",
    "lines_to_next_cell": 2,
    "outputId": "e1b14b62-736d-49c3-d73d-796d404d69a5"
   },
   "outputs": [],
   "source": [
    "def predict(bedrooms, bathrooms, longitude, latitude):\n",
    "\n",
    "    # Make dataframe from the inputs\n",
    "    df = pd.DataFrame(\n",
    "        data=[[bedrooms, bathrooms, longitude, latitude]], \n",
    "        columns=['bedrooms', 'bathrooms', 'longitude', 'latitude']\n",
    "    )\n",
    "\n",
    "    # Get the model's prediction\n",
    "    pred = model.predict(df)[0]\n",
    "\n",
    "    # Calculate shap values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(df)\n",
    "\n",
    "    # Get series with shap values, feature names, & feature values\n",
    "    feature_names = df.columns\n",
    "    feature_values = df.values[0]\n",
    "    shaps = pd.Series(shap_values[0], zip(feature_names, feature_values))\n",
    "\n",
    "    # Print results\n",
    "    result = f'${pred:,.0f} estimated rent for this NYC apartment. \\n\\n'\n",
    "    result += f'Starting from baseline of ${explainer.expected_value:,.0f} \\n'\n",
    "    result += shaps.to_string()\n",
    "    print(result)\n",
    "\n",
    "\n",
    "    # Show shapley values force plot\n",
    "    shap.initjs()\n",
    "    return shap.force_plot(\n",
    "        base_value=explainer.expected_value, \n",
    "        shap_values=shap_values, \n",
    "        features=df\n",
    "    )\n",
    "\n",
    "predict(3, 1.5, -73.9425, 40.7145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "sxX3ZfZuE4PG",
    "outputId": "ccde08c5-b24c-47e8-86dc-d464550c887c"
   },
   "outputs": [],
   "source": [
    "# What if it was a 2 bedroom?\n",
    "predict(2, 1.5, -73.9425, 40.7145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "RU1JoEHnE4PH",
    "outputId": "93997cc5-eaee-4510-b2bc-9b8733457960"
   },
   "outputs": [],
   "source": [
    "# What if it was a 1 bedroom?\n",
    "predict(1, 1.5, -73.9425, 40.7145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WIK5iLlJE4PJ"
   },
   "source": [
    "## Classification: Lending Club 🏦\n",
    "\n",
    "This notebook uses Lending Club data, historical and current. Predict if peer-to-peer loans are charged off or fully paid. Decide which loans to invest in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9EnxwUeE4PJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Stratified sample, 10% of expired Lending Club loans, grades A-D\n",
    "# Source: https://www.lendingclub.com/info/download-data.action\n",
    "history = pd.read_csv(DATA_PATH+'lending-club/lending-club-subset.csv')\n",
    "history['issue_d'] = pd.to_datetime(history['issue_d'], infer_datetime_format=True)\n",
    "\n",
    "# Current loans available for manual investing, June 17, 2019\n",
    "# Source: https://www.lendingclub.com/browse/browse.action\n",
    "current = pd.read_csv(DATA_PATH+'../data/lending-club/primaryMarketNotes_browseNotes_1-RETAIL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moPSgqqpE4PL"
   },
   "outputs": [],
   "source": [
    "# Transform earliest_cr_line to an integer:\n",
    "# How many days the earliest credit line was open, before the loan was issued.\n",
    "# For current loans available for manual investing, assume the loan will be issued today.\n",
    "history['earliest_cr_line'] = pd.to_datetime(history['earliest_cr_line'], infer_datetime_format=True)\n",
    "history['earliest_cr_line'] = history['issue_d'] - history['earliest_cr_line']\n",
    "history['earliest_cr_line'] = history['earliest_cr_line'].dt.days\n",
    "\n",
    "current['earliest_cr_line'] = pd.to_datetime(current['earliest_cr_line'], infer_datetime_format=True)\n",
    "current['earliest_cr_line'] = pd.Timestamp.today() - current['earliest_cr_line']\n",
    "current['earliest_cr_line'] = current['earliest_cr_line'].dt.days\n",
    "\n",
    "# Transform earliest_cr_line for the secondary applicant\n",
    "history['sec_app_earliest_cr_line'] = pd.to_datetime(history['sec_app_earliest_cr_line'], infer_datetime_format=True, errors='coerce')\n",
    "history['sec_app_earliest_cr_line'] = history['issue_d'] - history['sec_app_earliest_cr_line']\n",
    "history['sec_app_earliest_cr_line'] = history['sec_app_earliest_cr_line'].dt.days\n",
    "\n",
    "current['sec_app_earliest_cr_line'] = pd.to_datetime(current['sec_app_earliest_cr_line'], infer_datetime_format=True, errors='coerce')\n",
    "current['sec_app_earliest_cr_line'] = pd.Timestamp.today() - current['sec_app_earliest_cr_line']\n",
    "current['sec_app_earliest_cr_line'] = current['sec_app_earliest_cr_line'].dt.days\n",
    "\n",
    "# Engineer features for issue date year & month\n",
    "history['issue_d_year'] = history['issue_d'].dt.year\n",
    "history['issue_d_month'] = history['issue_d'].dt.month\n",
    "\n",
    "current['issue_d_year'] = pd.Timestamp.today().year\n",
    "current['issue_d_month'] = pd.Timestamp.today().month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHHdj7NEE4PM"
   },
   "outputs": [],
   "source": [
    "# Calculate percent of each loan repaid\n",
    "history['percent_paid'] = history['total_pymnt'] / history['funded_amnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uDNoPht3E4PO"
   },
   "outputs": [],
   "source": [
    "# Train on the historical data.\n",
    "# For the target, use `loan_status` ('Fully Paid' or 'Charged Off')\n",
    "target = 'loan_status'\n",
    "X = history.drop(columns=target)\n",
    "y = history[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "id": "tLqsPlEvE4PR",
    "outputId": "b08c42f7-a5b9-4225-aeff-101afe533a6d"
   },
   "outputs": [],
   "source": [
    "# Do train/validate/test 3-way split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=20000, stratify=y, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=20000, \n",
    "    stratify=y_trainval, random_state=42)\n",
    "\n",
    "print('X_train shape', X_train.shape)\n",
    "print('y_train shape', y_train.shape)\n",
    "print('X_val shape', X_val.shape)\n",
    "print('y_val shape', y_val.shape)\n",
    "print('X_test shape', X_test.shape)\n",
    "print('y_test shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDqfzApmE4PS"
   },
   "outputs": [],
   "source": [
    "# Save the ids for later, so we can look up actual results,\n",
    "# to compare with predicted results\n",
    "train_id = X_train['id']\n",
    "val_id = X_val['id']\n",
    "test_id = X_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LP62fXM9E4PT"
   },
   "outputs": [],
   "source": [
    "# Use Python sets to compare the historical columns & current columns\n",
    "common_columns = set(history.columns) & set(current.columns)\n",
    "just_history = set(history.columns) - set(current.columns)\n",
    "just_current = set(current.columns) - set(history.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uN1lj_iqE4PU"
   },
   "outputs": [],
   "source": [
    "# For features, use only the common columns shared by the historical & current data.\n",
    "features = list(common_columns)\n",
    "X_train = X_train[features]\n",
    "X_val = X_val[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "ofNmx23BE4PW",
    "outputId": "6a919a87-a5e5-46c4-845c-a751c83f16bc"
   },
   "outputs": [],
   "source": [
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "\n",
    "    # Engineer new feature for every feature: is the feature null?\n",
    "    for col in X:\n",
    "        X[col+'_NULL'] = X[col].isnull()\n",
    "    \n",
    "    # Convert percentages from strings to floats\n",
    "    X['int_rate'] = X['int_rate'].str.strip('%').astype(float)\n",
    "    X['revol_util'] = X['revol_util'].str.strip('%').astype(float)\n",
    "    \n",
    "    # Convert employment length from string to float\n",
    "    X['emp_length'] = X['emp_length'].str.replace(r'\\D','').astype(float)\n",
    "        \n",
    "    # Create features for three employee titles: teacher, manager, owner\n",
    "    X['emp_title'] = X['emp_title'].str.lower()\n",
    "    X['emp_title_teacher'] = X['emp_title'].str.contains('teacher', na=False)\n",
    "    X['emp_title_manager'] = X['emp_title'].str.contains('manager', na=False)\n",
    "    X['emp_title_owner']   = X['emp_title'].str.contains('owner', na=False)\n",
    "\n",
    "    # Get length of free text fields\n",
    "    X['title'] = X['title'].str.len()\n",
    "    X['desc'] = X['desc'].str.len()\n",
    "    X['emp_title'] = X['emp_title'].str.len()\n",
    "    \n",
    "    # Convert sub_grade from string \"A1\"-\"D5\" to numbers\n",
    "    sub_grade_ranks = {'A1': 1.1, 'A2': 1.2, 'A3': 1.3, 'A4': 1.4, 'A5': 1.5, \n",
    "                       'B1': 2.1, 'B2': 2.2, 'B3': 2.3, 'B4': 2.4, 'B5': 2.5, \n",
    "                       'C1': 3.1, 'C2': 3.2, 'C3': 3.3, 'C4': 3.4, 'C5': 3.5, \n",
    "                       'D1': 4.1, 'D2': 4.2, 'D3': 4.3, 'D4': 4.4, 'D5': 4.5}\n",
    "    X['sub_grade'] = X['sub_grade'].map(sub_grade_ranks)\n",
    "    \n",
    "    # Drop some columns\n",
    "    X = X.drop(columns='id')        # Always unique\n",
    "    X = X.drop(columns='url')       # Always unique\n",
    "    X = X.drop(columns='member_id') # Always null\n",
    "    X = X.drop(columns='grade')     # Duplicative of sub_grade\n",
    "    X = X.drop(columns='zip_code')  # High cardinality\n",
    "    \n",
    "    # Only use these features which had nonzero permutation importances in earlier models    \n",
    "    features = ['acc_open_past_24mths', 'addr_state', 'all_util', 'annual_inc', \n",
    "                'annual_inc_joint', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', \n",
    "                'collections_12_mths_ex_med', 'delinq_amnt', 'desc_NULL', 'dti', \n",
    "                'dti_joint', 'earliest_cr_line', 'emp_length', 'emp_length_NULL', \n",
    "                'emp_title', 'emp_title_NULL', 'emp_title_owner', 'fico_range_high', \n",
    "                'funded_amnt', 'home_ownership', 'inq_last_12m', 'inq_last_6mths', \n",
    "                'installment', 'int_rate', 'issue_d_month', 'issue_d_year', 'loan_amnt', \n",
    "                'max_bal_bc', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', \n",
    "                'mo_sin_rcnt_rev_tl_op', 'mort_acc', 'mths_since_last_major_derog_NULL', \n",
    "                'mths_since_last_record', 'mths_since_recent_bc', 'mths_since_recent_inq', \n",
    "                'num_actv_bc_tl', 'num_actv_rev_tl', 'num_op_rev_tl', 'num_rev_tl_bal_gt_0', \n",
    "                'num_tl_120dpd_2m_NULL', 'open_rv_12m_NULL', 'open_rv_24m', \n",
    "                'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'purpose', \n",
    "                'revol_bal', 'revol_bal_joint', 'sec_app_earliest_cr_line', \n",
    "                'sec_app_fico_range_high', 'sec_app_open_acc', 'sec_app_open_act_il', \n",
    "                'sub_grade', 'term', 'title', 'title_NULL', 'tot_coll_amt', \n",
    "                'tot_hi_cred_lim', 'total_acc', 'total_bal_il', 'total_bc_limit', \n",
    "                'total_cu_tl', 'total_rev_hi_lim']    \n",
    "    X = X[features]\n",
    "    \n",
    "    # Reset index\n",
    "    X = X.reset_index(drop=True)\n",
    "    \n",
    "    # Return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "\n",
    "X_train = wrangle(X_train)\n",
    "X_val   = wrangle(X_val)\n",
    "X_test  = wrangle(X_test)\n",
    "\n",
    "print('X_train shape', X_train.shape)\n",
    "print('X_val shape', X_val.shape)\n",
    "print('X_test shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lFme7R1hE4PY",
    "outputId": "6210e23e-c43c-4afa-c29a-be8bda42f6f6"
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "processor = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "X_train_processed = processor.fit_transform(X_train)\n",
    "X_val_processed = processor.transform(X_val)\n",
    "\n",
    "eval_set = [(X_train_processed, y_train), \n",
    "            (X_val_processed, y_val)]\n",
    "\n",
    "model = XGBClassifier(n_estimators=1000, n_jobs=-1)\n",
    "model.fit(X_train_processed, y_train, eval_set=eval_set, eval_metric='auc', \n",
    "          early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "_Bzpu_UnE4PZ",
    "lines_to_next_cell": 2,
    "outputId": "8d4ef9f1-442f-45b2-8c8a-0506bc8fc9a5"
   },
   "outputs": [],
   "source": [
    "# THIS CELL ISN'T ABOUT THE NEW OBJECTIVES FOR TODAY\n",
    "# BUT IT IS IMPORTANT FOR YOUR SPRINT CHALLENGE\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X_test_processed = processor.transform(X_test)\n",
    "class_index = 1\n",
    "y_pred_proba = model.predict_proba(X_test_processed)[:, class_index]\n",
    "print(f'Test ROC AUC for class {class_index}:')\n",
    "print(roc_auc_score(y_test, y_pred_proba)) # Ranges from 0-1, higher is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZN7KjTdE4Pa"
   },
   "source": [
    "### Look at predictions vs actuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zzfBDR6sE4Pa"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'id': test_id, \n",
    "    'pred_proba': y_pred_proba, \n",
    "    'status_group': y_test\n",
    "})\n",
    "\n",
    "df = df.merge(\n",
    "     history[['id', 'issue_d', 'sub_grade', 'percent_paid', 'term', 'int_rate']], \n",
    "     how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "yChcSUlqE4Pb",
    "outputId": "cbabccdf-5d4c-43b0-f40d-e84babca4316"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmZIJPkiE4Pc",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fully_paid = df['status_group'] == 'Fully Paid'\n",
    "charged_off = ~fully_paid\n",
    "right = (fully_paid) == (df['pred_proba'] > 0.50)\n",
    "wrong = ~right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MLj6i9dfE4Pe"
   },
   "source": [
    "#### Loan was fully paid, model's prediction was right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "Aj4wOoaIE4Pf",
    "lines_to_next_cell": 2,
    "outputId": "b2ae8afb-e40b-42b7-a04e-a0432cfba49e"
   },
   "outputs": [],
   "source": [
    "df[fully_paid & right].sample(n=10, random_state=1).sort_values(by='pred_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "TkEKFftnE4Pg",
    "outputId": "cdc60035-eec1-4cdd-a93b-51daaf200dad"
   },
   "outputs": [],
   "source": [
    "# To explain the prediction for test observation with index #3094, \n",
    "# first, get all of the features for that observation\n",
    "row = X_test.iloc[[3094]]\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ftf9g5G7E4Ph"
   },
   "source": [
    "## Explain individual predictions with shapley value plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "colab_type": "code",
    "id": "OHrS7JxAE4Ph",
    "outputId": "c826040f-acc2-4ce8-d362-6c13be8a3041"
   },
   "outputs": [],
   "source": [
    "# STUDY/PRACTICE THIS CELL FOR THE SPRINT CHALLENGE\n",
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "row_processed = processor.transform(row)\n",
    "shap_values = explainer.shap_values(row_processed)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value, \n",
    "    shap_values=shap_values, \n",
    "    features=row, \n",
    "    link='logit' # For classification, this shows predicted probabilities\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DsFBTseE4Pi"
   },
   "source": [
    "## BONUS: Make a function to explain predictions\n",
    "\n",
    "Goal Output:\n",
    "\n",
    "```\n",
    "The model predicts this loan is Fully Paid, with 74% probability.\n",
    " \n",
    " \n",
    "Top 3 reasons for prediction:\n",
    "1. dti is 10.97.\n",
    "2. term is  36 months.\n",
    "3. total_acc is 45.0.\n",
    " \n",
    " \n",
    "Top counter-argument against prediction:\n",
    "- sub_grade is 4.2.\n",
    " \n",
    "<INSERT SHAPLEY VALUE FORCE PLOT HERE>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "Cs_5Gv2nE4Pj",
    "outputId": "4a6b16ac-2a5a-4208-d456-ce0695528b10"
   },
   "outputs": [],
   "source": [
    "feature_names = row.columns\n",
    "feature_values = row.values[0]\n",
    "shaps = pd.Series(shap_values[0], zip(feature_names, feature_values))\n",
    "shaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-0s1jrjE4Pk"
   },
   "outputs": [],
   "source": [
    "pros = shaps.sort_values(ascending=False)[:3].index\n",
    "cons = shaps.sort_values(ascending=True)[:3].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "UP8Xq4sPiFjc",
    "outputId": "829d9d3a-9415-4eeb-fd7f-87de12068049"
   },
   "outputs": [],
   "source": [
    "pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "P2KYETvAiGoJ",
    "outputId": "aa7790c8-c641-444d-cc6e-68faca6e2d7b"
   },
   "outputs": [],
   "source": [
    "cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "elPLlN46E4Pl",
    "outputId": "bd2fb608-776a-4983-9dfe-34f268644ed1"
   },
   "outputs": [],
   "source": [
    "print('Top 3 reasons for fully paid:')\n",
    "for i, pro in enumerate(pros, start=1):\n",
    "    feature_name, feature_value = pro\n",
    "    print(f'{i}. {feature_name} is {feature_value}.')\n",
    "\n",
    "print('\\n')\n",
    "print('Cons:')\n",
    "for i, con in enumerate(cons, start=1):\n",
    "    feature_name, feature_value = con\n",
    "    print(f'{i}. {feature_name} is {feature_value}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "bVC36r1KE4Po",
    "outputId": "e351470f-327a-4bd6-8661-b878d40611db"
   },
   "outputs": [],
   "source": [
    "def explain(row_number):\n",
    "    positive_class = 'Fully Paid'\n",
    "    positive_class_index = 1\n",
    "\n",
    "    # Get & process the data for the row\n",
    "    row = X_test.iloc[[row_number]]\n",
    "    row_processed = processor.transform(row)\n",
    "\n",
    "    # Make predictions (includes predicted probability)\n",
    "    pred = model.predict(row_processed)[0]\n",
    "    pred_proba = model.predict_proba(row_processed)[0, positive_class_index]\n",
    "    pred_proba *= 100\n",
    "    if pred != positive_class:\n",
    "        pred_proba = 100 - pred_proba\n",
    "\n",
    "    # Show prediction & probability\n",
    "    print(f'The model predicts this loan is {pred}, with {pred_proba:.0f}% probability.')\n",
    "    \n",
    "    # Get shapley additive explanations\n",
    "    shap_values = explainer.shap_values(row_processed)\n",
    "\n",
    "    # Get top 3 \"pros & cons\" for fully paid\n",
    "    feature_names = row.columns\n",
    "    feature_values = row.values[0]\n",
    "    shaps = pd.Series(shap_values[0], zip(feature_names, feature_values))\n",
    "    pros = shaps.sort_values(ascending=False)[:3].index\n",
    "    cons = shaps.sort_values(ascending=True)[:3].index\n",
    "\n",
    "    # Show top 3 reason for prediction\n",
    "    print('\\n')\n",
    "    print('Top 3 reasons for prediction:')\n",
    "    evidence = pros if pred == positive_class else cons\n",
    "    for i, info in enumerate(evidence, start=1):\n",
    "        feature_name, feature_value = info\n",
    "        print(f'{i}. {feature_name} is {feature_value}.')\n",
    "\n",
    "    # Show top 1 counter-argument against prediction\n",
    "    print('\\n')\n",
    "    print('Top counter-argument against prediction:')\n",
    "    evidence = cons if pred == positive_class else pros\n",
    "    feature_name, feature_value = evidence[0]\n",
    "    print(f'- {feature_name} is {feature_value}.')\n",
    "\n",
    "    # Show Shapley Values Force Plot\n",
    "    shap.initjs()\n",
    "    return shap.force_plot(\n",
    "        base_value=explainer.expected_value, \n",
    "        shap_values=shap_values, \n",
    "        features=row, \n",
    "        link='logit' # For classification, this shows predicted probabilities\n",
    "    )\n",
    "\n",
    "explain(3094)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ditf1rS-E4Pp"
   },
   "source": [
    "## Look at more examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y33gLPmJE4Pp"
   },
   "source": [
    "#### Loan was charged off, model's prediction was right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "N6XcsKpeE4Pq",
    "lines_to_next_cell": 2,
    "outputId": "7601caf6-78ca-4112-b4ee-9265a485d143"
   },
   "outputs": [],
   "source": [
    "df[charged_off & right].sample(n=10, random_state=1).sort_values(by='pred_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "Z3p4MR1DE4Pr",
    "outputId": "4a77d813-aa27-4007-a24e-89b2724a54df"
   },
   "outputs": [],
   "source": [
    "explain(8383)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhNOg0XpE4Pr"
   },
   "source": [
    "#### Loan was fully paid, model's prediction was wrong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "BN5FBgfUE4Ps",
    "lines_to_next_cell": 2,
    "outputId": "538e409d-b9b3-45c0-e6f7-d55eac1c5b5c"
   },
   "outputs": [],
   "source": [
    "df[fully_paid & wrong].sample(n=10, random_state=1).sort_values(by='pred_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "rvOdFLWXE4Pt",
    "outputId": "c1adf09d-387b-4f43-dd15-c144d3cee671"
   },
   "outputs": [],
   "source": [
    "explain(18061)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "s_D6-ZcAE4Pv",
    "outputId": "cba02b6a-2a70-4d17-91d3-6a6a860f80ea"
   },
   "outputs": [],
   "source": [
    "explain(6763)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBqoiKCwE4Pw"
   },
   "source": [
    "#### Loan was charged off, model's prediction was wrong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "s2PoEp66E4Px",
    "outputId": "93f0b1a6-402b-4b9f-b962-5a923d3a1fd4"
   },
   "outputs": [],
   "source": [
    "df[charged_off & wrong].sample(n=10, random_state=1).sort_values(by='pred_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "EpW8AdrvE4Py",
    "outputId": "ddff370b-cfa9-4f50-e21f-fa67c7db21f3"
   },
   "outputs": [],
   "source": [
    "explain(19883)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist\n",
    "\n",
    "Don't let the perfect be the enemy of the good.\n",
    "\n",
    "## The Good\n",
    "\n",
    "- Publish a blog post\n",
    "\n",
    "- Choose a \n",
    "  - target, (**Poisonous or edible**)\n",
    "  - evaluation metric (**I shoose recall**), and \n",
    "  - baseline (**53.3% chance of being correct if we always guess 'edible'**)\n",
    "    \n",
    "  for a \n",
    "  - regression, \n",
    "  - binary classification **(THIS IS WHAT I CHOOSE)**, or \n",
    "  - multi-class classification problem, \n",
    "  \n",
    "  with their labeled, tabular dataset.\n",
    "  \n",
    "- Fit and evaluate\n",
    "  - any linear model \n",
    "  \n",
    "  for \n",
    "  \n",
    "  - regression or \n",
    "  - classification **(THIS IS WHAT I CHOOSE)**\n",
    "  \n",
    "- Fit and evaluate \n",
    "  - a decision tree, \n",
    "  - random forest, or \n",
    "  - gradient boosting model \n",
    "  \n",
    "  for regression or classification\n",
    "  \n",
    "  Student writes 300+ words (not including code). \n",
    "  \n",
    "  Student reports baseline score (**baseline is 53.3%**)\n",
    "  validation scores from 2+ models\n",
    "  - model 1\n",
    "  - model 2\n",
    "  and test score from 1 selected model\n",
    "  \n",
    "  \n",
    "  Student makes 2+ visualizations to explain their model\n",
    "  - viz one\n",
    "  \n",
    "  Student commits all code to GitHub. Notebooks have no error messages\n",
    "  \n",
    "  \n",
    "\n",
    "## The Perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "iUl0gWC9E4OY",
    "G6dptuu4E4Oi",
    "pchuM1I1E4O_",
    "N1ZB8yOGE4PE",
    "1DsFBTseE4Pi",
    "y33gLPmJE4Pp",
    "HhNOg0XpE4Pr",
    "YBqoiKCwE4Pw"
   ],
   "include_colab_link": true,
   "name": "is-this-poisonous.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
